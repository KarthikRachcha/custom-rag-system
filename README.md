# Custom RAG System

A lightweight, custom-built Retrieval-Augmented Generation (RAG) system built with Python. This system provides document-based question answering without external dependencies like LangChain or LangGraph.

## ğŸš€ Features

- **Multi-format Document Support**: TXT, PDF, DOCX files
- **Smart Text Chunking**: Intelligent document splitting with overlap
- **OpenAI Embeddings**: Uses OpenAI's text-embedding-ada-002 model
- **Vector Similarity Search**: Semantic search through document chunks
- **Fallback Text Search**: Basic keyword matching when embeddings fail
- **Interactive Interface**: Command-line Q&A system
- **Source Attribution**: Always shows where answers come from

## ğŸ—ï¸ Architecture

```
Document Loader â†’ Text Chunker â†’ Embedding System â†’ Vector Store â†’ Query Interface
      â†“              â†“              â†“              â†“            â†“
   Load files    Split chunks   Generate      Store &      Search &
   (TXT/PDF/    with overlap   embeddings    search       answer
    DOCX)
```

## ğŸ“‹ Requirements

- Python 3.8+
- OpenAI API key
- Internet connection for API calls

## ğŸ› ï¸ Installation

1. **Clone the repository:**
   ```bash
   git clone <your-repo-url>
   cd rag-system
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables:**
   Create a `.env` file in the project root:
   ```bash
   OPENAI_API_KEY=your_openai_api_key_here
   ```

4. **Add documents:**
   Place your documents in the `data/` folder

## ğŸš€ Usage

### Basic Usage

1. **Start the system:**
   ```bash
   python run.py
   ```

2. **Ask questions interactively:**
   ```
   Enter your question: What is this document about?
   ```

3. **Exit the system:**
   ```
   Enter your question: quit
   ```

### Supported File Formats

- **Text Files (.txt)**: Plain text documents
- **PDF Files (.pdf)**: Multi-page PDF documents
- **Word Documents (.docx)**: Microsoft Word files

### Example Workflow

1. **Upload documents** to `data/` folder
2. **Run the system** with `python run.py`
3. **Ask questions** about your documents
4. **Get answers** with source citations

## ğŸ“ Project Structure

```
rag-system/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Main application entry point
â”‚   â”œâ”€â”€ document_loader.py   # Document loading and parsing
â”‚   â”œâ”€â”€ text_chunker.py      # Text splitting and chunking
â”‚   â”œâ”€â”€ embedding_system.py  # OpenAI embeddings generation
â”‚   â”œâ”€â”€ vector_store.py      # Vector storage and similarity search
â”‚   â””â”€â”€ rag_pipeline.py      # Main RAG orchestration
â”œâ”€â”€ data/                    # Document storage folder
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ run.py                  # Quick start script
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

### Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key (required)

### Customization

- **Chunk Size**: Modify `chunk_size` in `text_chunker.py`
- **Overlap**: Adjust `overlap` in `text_chunker.py`
- **Search Results**: Change `top_k` parameter in query methods
- **Models**: Update OpenAI model names in the code

## ğŸ¯ How It Works

1. **Document Loading**: System scans `data/` folder for supported files
2. **Text Extraction**: Converts documents to plain text
3. **Chunking**: Splits text into manageable chunks with overlap
4. **Embedding**: Generates vector representations using OpenAI
5. **Storage**: Stores chunks and embeddings in memory
6. **Querying**: Searches for relevant chunks using similarity
7. **Response**: Generates answers based on retrieved context

## ğŸš¨ Limitations

- **Memory-based storage**: Data is lost when the program stops
- **API dependency**: Requires OpenAI API access
- **Document scope**: Only knows what's in your uploaded documents
- **No persistent storage**: Vector database is not saved to disk

## ğŸ”® Future Enhancements

- [ ] Persistent vector database storage
- [ ] Web interface
- [ ] Batch processing for large document collections
- [ ] Multiple embedding model support
- [ ] Document update and versioning
- [ ] Export/import functionality

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- OpenAI for providing the embedding and completion APIs
- The open-source community for inspiration and tools

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the existing issues
2. Create a new issue with detailed information
3. Include error messages and system information

---

**Happy Document Searching! ğŸ‰**
